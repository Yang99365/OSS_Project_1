# server/main.py

from fastapi import FastAPI, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response
from diffusers import StableDiffusionPipeline
from PIL import Image
import torch
import io
import os

from dotenv import load_dotenv
from openai import OpenAI

# -------------------------
# ğŸ”‘ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ & OpenAI í´ë¼ì´ì–¸íŠ¸
# -------------------------
load_dotenv()  # .envì—ì„œ OPENAI_API_KEY ì½ê¸°

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")  # ì ˆëŒ€ ì½”ë“œì— í‚¤ ì§ì ‘ ì“°ì§€ ë§ê¸°!
)


def refine_prompt(user_prompt: str) -> str:
    """
    OpenAI(GPT-4.1)ë¥¼ ì‚¬ìš©í•´ì„œ Stable Diffusionìš© ê³ í€„ í”„ë¡¬í”„íŠ¸ë¡œ í™•ì¥/ë³´ì •
    ì‹¤íŒ¨í•˜ë©´ ì›ë˜ í”„ë¡¬í”„íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
    """
    if not user_prompt:
        return "a high quality 2D game character illustration"

    try:
        resp = client.chat.completions.create(
            model="gpt-4.1",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "ë„ˆëŠ” Stable Diffusion í”„ë¡¬í”„íŠ¸ ìµœì í™” ì „ë¬¸ê°€ë‹¤. "
                        "ì‚¬ìš©ìê°€ ì ì€ ì§§ì€ ì„¤ëª…ì„, "
                        "ê³ í’ˆì§ˆ 2D ê²Œì„ ê·¸ë˜í”½(ì¼ëŸ¬ìŠ¤íŠ¸, ìŠ¤í”„ë¼ì´íŠ¸)ì— ì í•©í•œ "
                        "ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ êµ¬ì²´ì ìœ¼ë¡œ í™•ì¥í•´ë¼. "
                        "ìŠ¤íƒ€ì¼, ì¡°ëª…, êµ¬ë„, í™”ì§ˆ ë“±ì„ ìì„¸íˆ ì¨ë¼."
                    ),
                },
                {
                    "role": "user",
                    "content": f"ë‹¤ìŒ ì„¤ëª…ì„ Stable Diffusionìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ë°”ê¿”ì¤˜: {user_prompt}",
                },
            ],
            max_tokens=200,
        )
        refined = resp.choices[0].message.content.strip()
        return refined or user_prompt
    except Exception as e:
        print("[OpenAI í”„ë¡¬í”„íŠ¸ ë³´ì • ì˜¤ë¥˜]", e)
        return user_prompt


# -------------------------
# FastAPI ê¸°ë³¸ ì„¤ì •
# -------------------------

app = FastAPI()

# CORS : Streamlitì—ì„œ API í˜¸ì¶œ í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

MODEL_ID = "runwayml/stable-diffusion-v1-5"

print("ğŸ”¹ Stable Diffusion txt2img ëª¨ë¸ ë¡œë“œ ì¤‘...")
pipe = StableDiffusionPipeline.from_pretrained(
    MODEL_ID,
    torch_dtype=torch.float32
).to("cpu")
print("âœ… txt2img ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")


@app.post("/generate")
async def generate_image(prompt: str = Form(...)):
    """
    Stable Diffusion txt2img ì „ìš© ì—”ë“œí¬ì¸íŠ¸
    - ì—…ë¡œë“œ ì´ë¯¸ì§€ëŠ” ì ˆëŒ€ ì‚¬ìš© ì•ˆ í•¨
    - í”„ë¡¬í”„íŠ¸ëŠ” ë¨¼ì € OpenAIë¡œ ë³´ì •í•œ í›„ SDì— ì „ë‹¬
    """

    # 1) OpenAIë¡œ í”„ë¡¬í”„íŠ¸ ë³´ì •
    refined_prompt = refine_prompt(prompt)
    print("ğŸ§  ì›ë³¸ í”„ë¡¬í”„íŠ¸ :", prompt)
    print("âœ¨ ë³´ì •ëœ í”„ë¡¬í”„íŠ¸ :", refined_prompt)

    # 2) Stable Diffusion txt2img í˜¸ì¶œ
    result = pipe(
        prompt=refined_prompt,
        num_inference_steps=30,
        guidance_scale=7.5,
    )

    img = result.images[0]

    buf = io.BytesIO()
    img.save(buf, format="PNG")
    buf.seek(0)

    return Response(content=buf.getvalue(), media_type="image/png")
